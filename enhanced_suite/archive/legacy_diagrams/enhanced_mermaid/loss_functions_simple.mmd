%% Enhanced Loss Functions Architecture - Simplified
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#d32f2f', 'primaryTextColor': '#ffffff', 'primaryBorderColor': '#b71c1c', 'lineColor': '#757575', 'secondaryColor': '#7b1fa2', 'tertiaryColor': '#1976d2', 'background': '#f5f5f5'}}}%%
graph TB
    subgraph "üîÑ <b><font color=#d32f2f>RECONSTRUCTION LOSS PIPELINE</font></b>"
        A[<b>Ground Truth</b><br/>x in R^(320√ó320√ó1)<br/>Original radio map] --> B[<b>VAE Reconstruction</b><br/>x_hat in R^(320√ó320√ó1)<br/>Generated output]
        B --> C[<b>L1 Loss</b><br/>L_L1 = |x - x_hat|<br/>Robust to outliers]
        B --> D[<b>MSE Loss</b><br/>L_MSE = ||x - x_hat||^2<br/>Sensitive to errors]
        C --> E[<b>Reconstruction Loss</b><br/>L_rec = L_L1 + L_MSE<br/>Combined objective]
        D --> E
    end
    
    subgraph "üß† <b><font color=#7b1fa2>PERCEPTUAL LOSS INTEGRATION</font></b>"
        F[<b>Input Images</b><br/>x, x_hat in R^(320√ó320√ó1)<br/>Original & reconstructed] --> G[<b>LPIPS Network</b><br/>Pre-trained VGG<br/>Feature extraction]
        H[<b>Feature Maps</b><br/>phi(x), phi(x_hat) in R^D<br/>Deep representations] --> I[<b>Perceptual Distance</b><br/>L_perceptual = ||phi(x) - phi(x_hat)||^2<br/>Human perception]
        G --> H
        I --> J[<b>Weighted Addition</b><br/>L_total = L_rec + lambda_p¬∑L_perceptual<br/>Multi-objective]
    end
    
    subgraph "üìä <b><font color=#1976d2>KL DIVERGENCE COMPONENTS</font></b>"
        K[<b>Encoder Parameters</b><br/>mu_phi(x), sigma_phi(x)<br/>Mean and variance] --> L[<b>Posterior Distribution</b><br/>q(z|x) = N(mu, sigma^2 I)<br/>Approximate posterior]
        M[<b>Prior Distribution</b><br/>p(z) = N(0, I)<br/>Standard normal] --> N[<b>KL Divergence</b><br/>KL[q||p] = 1/2 sum(mu^2 + sigma^2 - log(sigma^2) - 1)<br/>Information bottleneck]
        L --> N
        N --> O[<b>Batch Mean</b><br/>L_KL = E_B[KL(q||p)]<br/>Regularization]
        O --> P[<b>Weighted KL</b><br/>lambda_KL¬∑L_KL<br/>Trade-off parameter]
    end
    
    subgraph "‚öîÔ∏è <b><font color=#388e3c>ADVERSARIAL TRAINING</font></b>"
        Q[<b>VAE Generator</b><br/>G_phi: x -> z -> x_hat<br/>Reconstruction model] --> R[<b>Generated Samples</b><br/>x_hat = G_phi(x)<br/>Reconstructed output]
        R --> S[<b>Discriminator</b><br/>D_psi: R^(320√ó320) -> [0,1]<br/>Real vs fake classifier]
        S --> T[<b>Discriminator Output</b><br/>D_psi(x_hat) in R<br/>Fake logits]
        T --> U[<b>Generator Loss</b><br/>L_adv = -E[log(D_psi(G_phi(x)))]<br/>Adversarial objective]
    end
    
    E --> J
    P --> J
    U --> J
    
    style A fill:#FFEBEE,stroke:#D32F2F,stroke-width:3px,color:#000000
    style F fill:#F3E5F5,stroke:#7B1FA2,stroke-width:3px,color:#000000
    style K fill:#E3F2FD,stroke:#1976D2,stroke-width:3px,color:#000000
    style Q fill:#E8F5E8,stroke:#388E3C,stroke-width:3px,color:#000000
    
    classDef mathFormula fill:#FFF9C4,stroke:#F57F17,stroke-width:2px,color:#000000
    class C,D,E,G,I,N,O,P,S,T,U mathFormula