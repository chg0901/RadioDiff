%% Enhanced Conditional U-Net Architecture - 16:9 aspect ratio
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#1976d2', 'primaryTextColor': '#ffffff', 'primaryBorderColor': '#0d47a1', 'lineColor': '#757575', 'secondaryColor': '#388e3c', 'tertiaryColor': '#f57c00', 'background': '#f5f5f5'}}}%%
graph TB
    subgraph "üéõÔ∏è <b><font color=#1976d2>CONDITIONAL U-NET INPUT PROCESSING</font></b>"
        A[<b>Noisy Latent Input</b><br/><font color=#666>x_t ‚àà ‚Ñù^(B√ó3√ó80√ó80)</font><br/><i>Diffusion timestep t</i>] --> B[<b>Time Embedding</b><br/><font color=#666>sinusoidal(pos)</font><br/><i>Positional encoding</i>]
        B --> C[<b>Condition Integration</b><br/><font color=#666>c ‚àà ‚Ñù^(B√ó3√ó320√ó320)</font><br/><i>Building layout info</i>]
        C --> D[<b>Multi-modal Fusion</b><br/><font color=#666>[x_t; t; c]</font><br/><i>Concatenated input</i>]
    end
    
    subgraph "üîß <b><font color=#388e3c>SWIN TRANSFORMER BLOCKS</font></b>"
        E[<b>Window Attention 1</b><br/><font color=#666>Window: [8,8]</font><br/><i>Coarse-grained features</i>] --> F[<b>Window Attention 2</b><br/><font color=#666>Window: [4,4]</font><br/><i>Medium-grained features</i>]
        F --> G[<b>Window Attention 3</b><br/><font color=#666>Window: [2,2]</font><br/><i>Fine-grained features</i>]
        G --> H[<b>Window Attention 4</b><br/><font color=#666>Window: [1,1]</font><br/><i>Pixel-level attention</i>]
    end
    
    subgraph "üåä <b><font color=#f57c00>MULTI-SCALE FEATURE PROCESSING</font></b>"
        I[<b>Downsampling Path</b><br/><font color=#666>dim_mults: [1,2,4,4]</font><br/><i>Feature extraction</i>] --> J[<b>Bottleneck</b><br/><font color=#666>Maximum receptive field</font><br/><i>Global context</i>]
        J --> K[<b>Upsampling Path</b><br/><font color=#666>Skip connections</font><br/><i>Detail restoration</i>]
        K --> L[<b>Multi-scale Output</b><br/><font color=#666>Hierarchical features</font><br/><i>Rich representation</i>]
    end
    
    subgraph "üì° <b><font color=#d32f2f>ADAPTIVE FFT MODULE</font></b>"
        M[<b>Spatial Features</b><br/><font color=#666>Real-space representation</font><br/><i>Local patterns</i>] --> N[<b>Fourier Transform</b><br/><font color=#666>‚Ñ±(x) = ‚à´x(t)e^(-iœât)dt</font><br/><i>Frequency domain</i>]
        N --> O[<b>Frequency Processing</b><br/><font color=#666>Scale: 16</font><br/><i>Multi-resolution analysis</i>]
        O --> P[<b>Inverse Fourier</b><br/><font color=#666>‚Ñ±^(-1)(X) = (1/2œÄ)‚à´X(œâ)e^(iœât)dœâ</font><br/><i>Spatial reconstruction</i>]
    end
    
    subgraph "üéØ <b><font color=#7b1fa2>NOISE PREDICTION OUTPUT</font></b>"
        Q[<b>Feature Integration</b><br/><font color=#666>Spatial + Frequency</font><br/><i>Multi-domain fusion</i>] --> R[<b>Noise Prediction Head</b><br/><font color=#666>Œµ_Œ∏(x_t, t, c)</font><br/><i>Knowledge-aware</i>]
        R --> S[<b>Output Dimensions</b><br/><font color=#666>B√ó3√ó80√ó80</font><br/><i>Latent space</i>]
    end
    
    D --> E
    H --> I
    L --> M
    P --> Q
    
    %% Style definitions
    style A fill:#E3F2FD,stroke:#1976D2,stroke-width:3px,color:#000000
    style E fill:#E8F5E8,stroke:#388E3C,stroke-width:3px,color:#000000
    style I fill:#FFF3E0,stroke:#F57C00,stroke-width:3px,color:#000000
    style M fill:#FFEBEE,stroke:#D32F2F,stroke-width:3px,color:#000000
    style Q fill:#F3E5F5,stroke:#7B1FA2,stroke-width:3px,color:#000000
    
    %% Mathematical formula styling
    classDef mathFormula fill:#FFF9C4,stroke:#F57F17,stroke-width:2px,color:#000000
    class B,N,O,P,R mathFormula